  // reportIf('керівний числівник не nummod:gov',
  //   x => x.rel === 'nummod'
  //     && x.interp.isCardinalNumeral()
  //     && !x.interp.isPronoun()
  //     && (x.interp.isNominative() || x.interp.isAccusative() /*|| /^\d+$/.test(x.form)*/)
  //     && sentence[x.head].interp.isGenitive())

  //------------------------------------------------------------------------------
function formatProblemsTxt(docName: string, sentenceId: string, tokens: Token[], problems: any[], count: number) {
  let tokenWithDepsrc = tokens.find(x => x.getAttribute('depsrc'))
  let bratPath = tokenWithDepsrc && tokenWithDepsrc.getAttribute('depsrc').slice('/Users/msklvsk/Desktop/treebank/'.length, -4)
  let href = `https://lab.mova.institute/brat/index.xhtml#/ud/${bratPath}`
  let ret = `*** [${count}] Проблеми в реченні ${sentenceId} ${href}\n\n`
  let repro = tokens.join(' ')
  for (let { indexes, message } of problems) {
    ret += `    ${message}\n`
    ret += `${repro}\n`
    if (indexes !== undefined) {
      for (let j = 0; j < tokens.length; ++j) {
        let char = indexes.includes(j) ? '~' : ' '
        ret += char.repeat(tokens[j].form.length) + ' '
      }
      ret += '\n'
    }
  }
  ret += '\n'
  return ret
}


   temp-calculate text lengthes
      for (let chunk of root.evaluateElements(`//*[@src]`)) {
        let src = chunk.attribute('src')
        if (!src || sett.has(src)) {
          continue
        }
        sett.add(src)
        let count = chunk.evaluateNumber(`count(.//w_)`) || chunk.evaluateNumber(`count(.//w)`)
        if (!count) {
          tokenizeTei(chunk, analyzer)
          count = chunk.evaluateNumber(`count(.//w)`)
        }
        count += chunk.evaluateNumber(`count(.//pc)`)
        console.log(`${src}\t${count}`)
      }
      continue




//------------------------------------------------------------------------------
function adoptBratRelationsNoN() {
  let [xmlFile, bratFilesGlob, nStr] = process.argv.slice(2)
  let bratFiles = glob.sync(bratFilesGlob)
  let n = Number.parseInt(nStr)
  let root = parseXmlFileSync(xmlFile)
  bratFiles.sort((a, b) => Number(a.match(/zerov_(\d+)\./)[1]) - Number(b.match(/zerov_(\d+)\./)[1]))
  console.log(bratFiles)

  for (let bratFile of bratFiles) {
    let ann = parseBratFile(linesSync(bratFile))
    let tokens = [...root.evaluateElements('//mi:w_|//tei:pc', NS)]
    // console.log(ann)
    // console.log(tokens)

    for (let i = 0; i < ann.length; ++i) {
      if (ann[i].relation) {
        let headEl = tokens[n + ann[i].head.i]
        let headN = headEl.attribute('n')
        let dep = `${headN}-${ann[i].relation}`
        tokens[n + ann[i].i].setAttribute('dep', dep)
      }
    }
    n += ann.length
  }
  fs.writeFileSync(xmlFile, root.serialize() + '\n')
}


//------------------------------------------------------------------------------
function write4vec(outDir: string, relPath: string, parsedDocs: CorpusDoc[], analyzer: MorphAnalyzer) {
  let forvecPath = join(outDir, '4vec', `${relPath}.4vec`)
  let tempout = openSyncMkdirp(forvecPath, 'w')
  for (let parsedDoc of parsedDocs) {
    // add title to the body
    // if (parsedDoc.paragraphs.length && parsedDoc.paragraphs[0] !== parsedDoc.title) {
    //   parsedDoc.paragraphs = [parsedDoc.title, ...parsedDoc.paragraphs]
    // }

    for (let paragraph of parsedDoc.paragraphs) {
      let towrite = mu(nlpUtils.tokenizeUk(paragraph, analyzer))
        .map(({ token }) => token.trim())
        .filter(token => token && !nlpStatic.ANY_PUNC_OR_DASH_RE.test(token))
        .join(' ')
      fs.writeSync(tempout, towrite + '\n')
    }
  }
  fs.closeSync(tempout)
}

//------------------------------------------------------------------------------
function umoloda(workspacePath: string, analyzer: MorphAnalyzer) {
  let verticalFile = rotateAndOpen(join(workspacePath, `build/ umoloda.vrt.txt`))
  let articlePathsGlob = join(workspacePath, 'data/umoloda/fetched_articles/*.html')
  let articlePaths = globSync(articlePathsGlob).sort(umolodaFilenameComparator)
  for (let path of articlePaths) {
    let [a, b, c] = trimExtension(basename(path)).split('_')
    console.log(`processing umoloda article ${a}_${b}_${c}`)

    let html = fs.readFileSync(path, 'utf8')
    let { title, author, paragraphs, date } = parseUmolodaArticle(html, htmlDocCreator)

    if (!paragraphs.length) {  // some empty articles happen
      continue
    }

    date = date.split('.').reverse().join('–')
    let meta = {
      // publisher: 'Україна молода',
      // proofread: '✓',
      url: `http://www.umoloda.kiev.ua/number/${a}/${b}/${c}/`,
      author,
      title,
      reference_title: title ? `УМ:${title}` : `УМ`,
      date,
      type: 'публіцистика',
    }
    writeDocMetaAndParagraphs(meta, paragraphs, analyzer, verticalFile)
  }
}

//------------------------------------------------------------------------------
function den(workspacePath: string, analyzer: MorphAnalyzer) {
  let verticalFile = rotateAndOpen(join(workspacePath, `build/den.vrt.txt`))
  let articlePathsGLob = join(workspacePath, 'data/den/fetched_articles/*/**/*.html')
  let articlePaths = globSync(articlePathsGLob)

  for (let path of articlePaths) {
    console.log(`processing den article ${trimExtension(basename(path))}`)

    try {
      let html = fs.readFileSync(path, 'utf8')
      var { author, date, paragraphs, title, url, valid } = parseDenArticle(html, htmlDocCreator)
    } catch (e) {
      console.error(`Error: ${e.message}`)
      continue
    }
    if (!valid) {
      continue
    }

    let meta = {
      // publisher: 'День',
      // proofread: '✓',
      url,
      author,
      title,
      reference_title: `Д.: ${title}`,
      date,
      type: 'публіцистика',
    }
    writeDocMetaAndParagraphs(meta, paragraphs, analyzer, verticalFile)
  }
}




//------------------------------------------------------------------------------
function tyzhden(workspacePath: string, analyzer: MorphAnalyzer) {
  let verticalFile = rotateAndOpen(join(workspacePath, 'build', 'tyzhden.vrt.txt'))
  let articlePathsGLob = join(workspacePath, 'data/tyzhden/html/**/*.html')
  let articlePaths = globSync(articlePathsGLob, { nosort: true })
    .sort((a, b) => Number(trimExtension(basename(a))) - Number(trimExtension(basename(b))))

  for (let path of articlePaths) {
    try {
      let html = fs.readFileSync(path, 'utf8')
      var { author, date, paragraphs, title, url, isValid } = parseTyzhdenArticle(html, htmlDocCreator)
    } catch (e) {
      console.error(`Error: ${e.stack}`)
      continue
    }
    if (!isValid) {
      continue
    }
    console.log(`processing tyzhden article ${url}`)

    let meta = {
      // publisher: 'Тиждень',
      // proofread: '✓',
      url,
      author,
      title,
      reference_title: `Т.: ${title}`,
      date,
      type: 'публіцистика',
    }

    writeDocMetaAndParagraphs(meta, paragraphs, analyzer, verticalFile)
  }
}

//------------------------------------------------------------------------------
function conllu2forvec(conllu: string) {
  let forms = ''
  let lemmas = ''

  for (let sent of conllu.trim().split('\n\n')) {
    let lines = sent.split('\n')
    let lenBefore = forms.length
    for (let i = 0, max = lines.length - 1; i <= max; ++i) {
      if (lines[i].startsWith('#')) {
        continue
      }
      let [, form, lemma, pos] = lines[i].split('\t', 4)
      if (pos === 'PUNCT') {
        continue
      }
      forms += form
      lemmas += lemma

      if (i !== max) {
        forms += ' '
        lemmas += ' '
      }
    }

    if (lenBefore < forms.length) {
      forms += '\n'
      lemmas += '\n'
    }
  }

  return { forms, lemmas }
}
