//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
// bin alternative (in development)
async function main2() {
  ignorePipeErrors()

  const binNewline = Buffer.from('\n')
  const binOne = Buffer.from('1')
  const binGap = Buffer.from('<gap type="dupe"/>\n')

  process.stdin.on('data', (buf: Buffer) => {
    let start = 0
    let end = -1
    while ((end = buf.indexOf(binNewline, start)) >= 0) {
      writeBackpressed(process.stdout, process.stdin, buf.slice(0, start))
      start = end + 1
      if (start < buf.length) {

      }
    }
  })
}

async function main0() {
  ignorePipeErrors()
  process.stdin.setEncoding('utf8')

  let insideGap = false
  await linesAsync(process.stdin, async lines => {
    for (let line of lines) {
      if (line.startsWith('1')) {
        insideGap = true
      } else if (insideGap) {
        writeBackpressed(process.stdout, process.stdin, `<gap type="dupe"/>\n`)
        insideGap = false
      } else {
        writeBackpressed(process.stdout, process.stdin, `${line.substr(2)}\n`)
      }
    }
  })
}

async function main1() {
  const binNewline = Buffer.from('\n')
  const binOne = Buffer.from('1')
  const binGap = Buffer.from('<gap type="dupe"/>\n')

  ignorePipeErrors()

  let insideGap = false
  await chunksAsync(process.stdin, async bufs => {
    for (let buf of bufs) {
      if (buf.readUInt8(0) === 49) {
        insideGap = true
      } else if (insideGap) {
        writeBackpressed(process.stdout, process.stdin, binGap)
        insideGap = false
      } else {
        writeBackpressed(process.stdout, process.stdin, buf.slice(2))
        writeBackpressed(process.stdout, process.stdin, binNewline)
      }
    }
  }, binNewline)
}

////////////////////////////////////////////////////////////////////////////////
export function forEachLine2(stream: NodeJS.ReadableStream, f: (line: string, cb: () => void) => void) {
  return new Promise<void>((resolve, reject) => {
    let rl = createInterface({ input: stream })

    let onLine = async (line: string) => {
      console.log(`onLine`)
      // rl.pause()
      await f(line, () => rl.once('line', onLine))
      // rl.resume()
      // rl.once('line', onLine)
    }

    rl.once('line', onLine)
      .on('close', resolve)
  })
}


// from chtyvo grabber

/*loop:
for (let format of extensionPriority) {
  for (let extension of [format, `${format}.zip`]) {
    let dataUrl = root.evaluateAttributes('//table[@class="books"]//a/@href')
      .map(x => parse(x.value()))
      .find(x => x && x.path.endsWith(`.${extension}`))
    if (dataUrl) {
      let filish = dataUrl.pathname.substr(1)
      if (!pages.has(filish)) {
        await pages.setStream(filish, get(dataUrl.href))
        console.log(`saved ${filish}`)
      }
      break loop
    }
  }
}*/

const TRANSFORMS = {
  toPart(el: AbstractElement) {
    el.firstElementChild().setAttribute('ana', 'part')
  },
  toConjSubord(el: AbstractElement) {
    el.firstElementChild().setAttribute('ana', 'conj:subord')
  },
  toAccusative(t: GraphNode<Token>) {
    let toChange = t.children.filter(x => uEq(x.node.rel, 'amod') || uEq(x.node.rel, 'det'))
    toChange.push(t)
    toChange.forEach(tt => tt.node.interp.setIsAccusative())
  },
  toGenitive(t: GraphNode<Token>) {
    let toChange = t.children.filter(x => uEq(x.node.rel, 'amod') || uEq(x.node.rel, 'det'))
    toChange.push(t)
    toChange.forEach(tt => tt.node.interp.setIsGenitive())
  },
  toObl(t: GraphNode<Token>) {
    t.node.rel = 'obl'
  },
  toDash(t: GraphNode<Token>) {
    t.node.interp.setFeature(f.PunctuationType, f.PunctuationType.dash)
  },
  toNDash(t: GraphNode<Token>) {
    t.node.interp.setFeature(f.PunctuationType, f.PunctuationType.ndash)
  },
  toHyphen(t: GraphNode<Token>) {
    t.node.interp.setFeature(f.PunctuationType, f.PunctuationType.hyphen)
  }
}

/*

//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function switch2globalIds(root: AbstractElement) {
  let tokens = [...root.evaluateElements('//w_')]

  let n2id = new Map<string, string>(
    tokens.map(x => [x.attribute('n'), x.attribute('id')] as [string, string])
  )

  for (let token of tokens) {
    let dep = token.attribute('dep')
    if (dep) {
      dep = dep.replace(/\d+/g, x => n2id.get(x))
      token.setAttribute('dep', dep)
    }
  }
  for (let token of tokens) {
    token.removeAttribute('n')
  }
}

//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function convertPcToW(root: AbstractElement) {
  mu(root.evaluateElements('//pc'))
    .forEach(pc => {
      let word = root.document().createElement('w_').setAttributes(pc.attributesObj())
      let interp = root.document().createElement('w').setAttributes({
        lemma: pc.text(),
        ana: 'punct'
      })
      interp.text(pc.text())
      word.appendChild(interp)
      pc.insertAfter(word)
      pc.remove()
    })
}

//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function sideQuotes(root: AbstractElement) {
  mu(root.evaluateElements('//w_'))
    .filter(x => x.firstElementChild().attribute('lemma') === '"')
    .forEach(interpEl => {
      let isOpeninig = interpEl.nextElementSibling()
        && interpEl.nextElementSibling().localName() === 'g'
        && !(interpEl.nextElementSibling().firstElementChild()
          && interpEl.nextElementSibling().firstElementChild().attribute('ana').startsWith('punct'))
      let isClosing = interpEl.previousElementSibling()
        && interpEl.previousElementSibling().localName() === 'g'
        && !(interpEl.previousElementSibling().firstElementChild()
          && interpEl.previousElementSibling().firstElementChild().attribute('ana').startsWith('punct'))
      if (isOpeninig === isClosing) {
        console.error(`fooooo id ${interpEl.attribute('id')}`)
      } else if (isOpeninig) {
        interpEl.firstElementChild().setAttribute('ana', 'punct:quote:open')
      } else if (isClosing) {
        interpEl.firstElementChild().setAttribute('ana', 'punct:quote:close')
      }
    })
}

// split tokens

tokens.forEach(el => {
  let t = $t(el)

  let interps = [...el.elementChildren()]
  if (interps.length === 1) {
    let form = t.text()
    let lemma = t.lemmaIfUnamb()
    if ((!lemma || !lemma.startsWith('будь-')) && /[^\-\d]-[^\-]/.test(form)) {
      if (!analyzer.tag(form).length) {
        el.insertBefore(el.firstElementChild().firstChild())
        el.remove()
      }
    }
  }
})
tokenizeTei(root, analyzer)
morphInterpret(root, analyzer)



*/

;[...root.evaluateElements('//sb')].forEach(sb => {
  if (!sb.nextElementSibling()) {
    if (sb.parent().evaluateElement('following-sibling::p')
      && sb.parent().evaluateElement('following-sibling::p').firstElementChild()
      && sb.parent().evaluateElement('following-sibling::p').firstElementChild().localName() === 'w_'
    ) {
      sb.parent().evaluateElement('following-sibling::p').firstElementChild().insertBefore(sb)
      // sb.insertBefore()
    } else {
      sb.remove()
    }
  }
});


//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function insertGlueAroundIfNeeded(el: AbstractElement) {
  if (el.text() === '-'
    && el.previousElementSibling()
    && el.nextElementSibling()
    && el.previousElementSibling().localName() !== 'g'
    && el.nextElementSibling().localName() !== 'g'
  ) {

  }
}

if (prevNode
  && prevNode.node.gluedNext
  && token.gluedNext
  && /[–—]/.test(token.form)
  && !interp.hasFeature(f.PunctuationType)
) {
  interp.setFeature(f.PunctuationType, f.PunctuationType.dash)
}

// if (!interp.hasFeature(f.PunctuationType)
//   && interp.isPunctuation()
//   && token.form === '-'
//   // && prevNode
//   // && prevNode.node.gluedNext
//   // && token.gluedNext
// ) {
//   interp.setFeature(f.PunctuationType, f.PunctuationType.dash)
// }

for (let tokenEl of tokenEls) {
  let docEl = tokenEl.evaluateElement('ancestor::doc[1]')
  // console.log(docEl.attribute('id'))

  if (tokenEl.firstElementChild().text() === '-'
    && tokenEl.previousElementSibling()
    && tokenEl.nextElementSibling()
    && tokenEl.previousElementSibling().localName() !== 'g'
    && tokenEl.nextElementSibling().localName() !== 'g'
    && '14fn 1h4e 1imh 1i47 1jlq 1ken 1rea'.split(' ').includes(docEl.attribute('id'))
  ) {
    tokenEl.insertBefore(tokenEl.document().createElement('g'))
    tokenEl.insertAfter(tokenEl.document().createElement('g'))
  }
}

// if (token.rel === 'xcomp'
//   && !interp.isVerb()
//   && !g2.isInfinitive(node)
//   && !g2.isInfinitiveCop(node)
// ) {
//   token.rel = 'xcomp:2'
// }

            // reportIf('керівний числівник не nummod:gov',
  //   x => x.rel === 'nummod'
  //     && x.interp.isCardinalNumeral()
  //     && !x.interp.isPronoun()
  //     && (x.interp.isNominative() || x.interp.isAccusative() /*|| /^\d+$/.test(x.form)*/)
  //     && sentence[x.head].interp.isGenitive())

  //^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function formatProblemsTxt(docName: string, sentenceId: string, tokens: Token[], problems: any[], count: number) {
  let tokenWithDepsrc = tokens.find(x => x.getAttribute('depsrc'))
  let bratPath = tokenWithDepsrc && tokenWithDepsrc.getAttribute('depsrc').slice('/Users/msklvsk/Desktop/treebank/'.length, -4)
  let href = `https://lab.mova.institute/brat/index.xhtml#/ud/${bratPath}`
  let ret = `*** [${count}] Проблеми в реченні ${sentenceId} ${href}\n\n`
  let repro = tokens.join(' ')
  for (let { indexes, message } of problems) {
    ret += `    ${message}\n`
    ret += `${repro}\n`
    if (indexes !== undefined) {
      for (let j = 0; j < tokens.length; ++j) {
        let char = indexes.includes(j) ? '~' : ' '
        ret += char.repeat(tokens[j].form.length) + ' '
      }
      ret += '\n'
    }
  }
  ret += '\n'
  return ret
}


   temp-calculate text lengthes
      for (let chunk of root.evaluateElements(`//*[@src]`)) {
        let src = chunk.attribute('src')
        if (!src || sett.has(src)) {
          continue
        }
        sett.add(src)
        let count = chunk.evaluateNumber(`count(.//w_)`) || chunk.evaluateNumber(`count(.//w)`)
        if (!count) {
          tokenizeTei(chunk, analyzer)
          count = chunk.evaluateNumber(`count(.//w)`)
        }
        count += chunk.evaluateNumber(`count(.//pc)`)
        console.log(`${src}\t${count}`)
      }
      continue




//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function adoptBratRelationsNoN() {
  let [xmlFile, bratFilesGlob, nStr] = process.argv.slice(2)
  let bratFiles = glob.sync(bratFilesGlob)
  let n = Number.parseInt(nStr)
  let root = parseXmlFileSync(xmlFile)
  bratFiles.sort((a, b) => Number(a.match(/zerov_(\d+)\./)[1]) - Number(b.match(/zerov_(\d+)\./)[1]))
  console.log(bratFiles)

  for (let bratFile of bratFiles) {
    let ann = parseBratFile(linesSync(bratFile))
    let tokens = [...root.evaluateElements('//mi:w_|//tei:pc', NS)]
    // console.log(ann)
    // console.log(tokens)

    for (let i = 0; i < ann.length; ++i) {
      if (ann[i].relation) {
        let headEl = tokens[n + ann[i].head.i]
        let headN = headEl.attribute('n')
        let dep = `${headN}-${ann[i].relation}`
        tokens[n + ann[i].i].setAttribute('dep', dep)
      }
    }
    n += ann.length
  }
  fs.writeFileSync(xmlFile, root.serialize() + '\n')
}


//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function write4vec(outDir: string, relPath: string, parsedDocs: CorpusDoc[], analyzer: MorphAnalyzer) {
  let forvecPath = join(outDir, '4vec', `${relPath}.4vec`)
  let tempout = openSyncMkdirp(forvecPath, 'w')
  for (let parsedDoc of parsedDocs) {
    // add title to the body
    // if (parsedDoc.paragraphs.length && parsedDoc.paragraphs[0] !== parsedDoc.title) {
    //   parsedDoc.paragraphs = [parsedDoc.title, ...parsedDoc.paragraphs]
    // }

    for (let paragraph of parsedDoc.paragraphs) {
      let towrite = mu(nlpUtils.tokenizeUk(paragraph, analyzer))
        .map(({ token }) => token.trim())
        .filter(token => token && !nlpStatic.ANY_PUNC_OR_DASH_RE.test(token))
        .join(' ')
      fs.writeSync(tempout, towrite + '\n')
    }
  }
  fs.closeSync(tempout)
}

//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function umoloda(workspacePath: string, analyzer: MorphAnalyzer) {
  let verticalFile = rotateAndOpen(join(workspacePath, `build/ umoloda.vrt.txt`))
  let articlePathsGlob = join(workspacePath, 'data/umoloda/fetched_articles/*.html')
  let articlePaths = globSync(articlePathsGlob).sort(umolodaFilenameComparator)
  for (let path of articlePaths) {
    let [a, b, c] = trimExtension(basename(path)).split('_')
    console.log(`processing umoloda article ${a}_${b}_${c}`)

    let html = fs.readFileSync(path, 'utf8')
    let { title, author, paragraphs, date } = parseUmolodaArticle(html, htmlDocCreator)

    if (!paragraphs.length) {  // some empty articles happen
      continue
    }

    date = date.split('.').reverse().join('–')
    let meta = {
      // publisher: 'Україна молода',
      // proofread: '✓',
      url: `http://www.umoloda.kiev.ua/number/${a}/${b}/${c}/`,
      author,
      title,
      reference_title: title ? `УМ:${title}` : `УМ`,
      date,
      type: 'публіцистика',
    }
    writeDocMetaAndParagraphs(meta, paragraphs, analyzer, verticalFile)
  }
}

//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function den(workspacePath: string, analyzer: MorphAnalyzer) {
  let verticalFile = rotateAndOpen(join(workspacePath, `build/den.vrt.txt`))
  let articlePathsGLob = join(workspacePath, 'data/den/fetched_articles/*/**/*.html')
  let articlePaths = globSync(articlePathsGLob)

  for (let path of articlePaths) {
    console.log(`processing den article ${trimExtension(basename(path))}`)

    try {
      let html = fs.readFileSync(path, 'utf8')
      var { author, date, paragraphs, title, url, valid } = parseDenArticle(html, htmlDocCreator)
    } catch (e) {
      console.error(`Error: ${e.message}`)
      continue
    }
    if (!valid) {
      continue
    }

    let meta = {
      // publisher: 'День',
      // proofread: '✓',
      url,
      author,
      title,
      reference_title: `Д.: ${title}`,
      date,
      type: 'публіцистика',
    }
    writeDocMetaAndParagraphs(meta, paragraphs, analyzer, verticalFile)
  }
}




//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function tyzhden(workspacePath: string, analyzer: MorphAnalyzer) {
  let verticalFile = rotateAndOpen(join(workspacePath, 'build', 'tyzhden.vrt.txt'))
  let articlePathsGLob = join(workspacePath, 'data/tyzhden/html/**/*.html')
  let articlePaths = globSync(articlePathsGLob, { nosort: true })
    .sort((a, b) => Number(trimExtension(basename(a))) - Number(trimExtension(basename(b))))

  for (let path of articlePaths) {
    try {
      let html = fs.readFileSync(path, 'utf8')
      var { author, date, paragraphs, title, url, isValid } = parseTyzhdenArticle(html, htmlDocCreator)
    } catch (e) {
      console.error(`Error: ${e.stack}`)
      continue
    }
    if (!isValid) {
      continue
    }
    console.log(`processing tyzhden article ${url}`)

    let meta = {
      // publisher: 'Тиждень',
      // proofread: '✓',
      url,
      author,
      title,
      reference_title: `Т.: ${title}`,
      date,
      type: 'публіцистика',
    }

    writeDocMetaAndParagraphs(meta, paragraphs, analyzer, verticalFile)
  }
}

//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
function conllu2forvec(conllu: string) {
  let forms = ''
  let lemmas = ''

  for (let sent of conllu.trim().split('\n\n')) {
    let lines = sent.split('\n')
    let lenBefore = forms.length
    for (let i = 0, max = lines.length - 1; i <= max; ++i) {
      if (lines[i].startsWith('#')) {
        continue
      }
      let [, form, lemma, pos] = lines[i].split('\t', 4)
      if (pos === 'PUNCT') {
        continue
      }
      forms += form
      lemmas += lemma

      if (i !== max) {
        forms += ' '
        lemmas += ' '
      }
    }

    if (lenBefore < forms.length) {
      forms += '\n'
      lemmas += '\n'
    }
  }

  return { forms, lemmas }
}
